{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMWgOTVYIPvni/9Pym1Rf5O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Split corpus in train, and test sets."],"metadata":{"id":"0wAdU2plf_2w"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TvGEwO7Rfbun"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["\"\"\"\n","Split a text corpus into training and evaluation sets.\n","\"\"\"\n","import os\n","import re\n","import argparse\n","import random\n","from pathlib import Path\n","from typing import List, Tuple\n","\n","def split_into_sentences(text: str) -> List[str]:\n","    # match sentence boundaries followed by spaces and capital letters\n","    sentence_pattern = r'(?<=[.!?])\\s+(?=[A-Z])'\n","    # split on the pattern, keep the separators\n","    sentences = re.split(sentence_pattern, text)\n","    # split by newlines for paragraphs and lists\n","    result = []\n","    for sentence in sentences:\n","        for line in sentence.split('\\n'):\n","            if line.strip():\n","                result.append(line.strip())\n","    return result\n","\n","def split_corpus(input_file: str, eval_size: float = 0.05, random_seed: int = 42, sentence_level: bool = True) -> Tuple[List[str], List[str]]:\n","    random.seed(random_seed)\n","    with open(input_file, 'r', encoding='utf-8') as f:\n","        content = f.read()\n","    # split into units (sentences or lines)\n","    if sentence_level:\n","        units = split_into_sentences(content)\n","        print(f\"Split corpus into {len(units)} sentences\")\n","    else:\n","        units = [line.strip() for line in content.split('\\n') if line.strip()]\n","        print(f\"Split corpus into {len(units)} lines\")\n","    random.shuffle(units)\n","    # calculate split point\n","    eval_count = max(1, int(len(units) * eval_size))\n","    # split corpus\n","    eval_units = units[:eval_count]\n","    train_units = units[eval_count:]\n","    print(f\"Training set: {len(train_units)} units ({100 - eval_size*100:.1f}%)\")\n","    print(f\"Evaluation set: {len(eval_units)} units ({eval_size*100:.1f}%)\")\n","    return train_units, eval_units\n","\n","def write_output_files(train_units: List[str], eval_units: List[str], output_dir: str, base_filename: str) -> Tuple[str, str]:\n","    os.makedirs(output_dir, exist_ok=True)\n","    base_name = Path(base_filename).stem\n","    train_path = os.path.join(output_dir, f\"{base_name}_train.txt\")\n","    eval_path = os.path.join(output_dir, f\"{base_name}_eval.txt\")\n","    with open(train_path, 'w', encoding='utf-8') as f:\n","        f.write('\\n'.join(train_units))\n","    with open(eval_path, 'w', encoding='utf-8') as f:\n","        f.write('\\n'.join(eval_units))\n","    train_size = os.path.getsize(train_path) / (1024 * 1024)\n","    eval_size = os.path.getsize(eval_path) / (1024 * 1024)\n","    print(f\"Training file size: {train_size:.2f} MB\")\n","    print(f\"Evaluation file size: {eval_size:.2f} MB\")\n","    return train_path, eval_path\n","\n","def validate_data_distribution(train_units: List[str], eval_units: List[str]) -> dict:\n","    train_chars = ''.join(train_units)\n","    eval_chars = ''.join(eval_units)\n","    train_unique_chars = set(train_chars)\n","    eval_unique_chars = set(eval_chars)\n","    eval_only_chars = eval_unique_chars - train_unique_chars\n","\n","    train_avg_len = sum(len(unit) for unit in train_units) / len(train_units) if train_units else 0\n","    eval_avg_len = sum(len(unit) for unit in eval_units) / len(eval_units) if eval_units else 0\n","\n","    train_words = ' '.join(train_units).split()\n","    eval_words = ' '.join(eval_units).split()\n","\n","    train_unique_words = set(train_words)\n","    eval_unique_words = set(eval_words)\n","\n","    eval_only_words = eval_unique_words - train_unique_words\n","    eval_only_words_pct = len(eval_only_words) / len(eval_unique_words) * 100 if eval_unique_words else 0\n","\n","    validation = {\n","        \"train_units\": len(train_units),\n","        \"eval_units\": len(eval_units),\n","        \"train_chars\": len(train_chars),\n","        \"eval_chars\": len(eval_chars),\n","        \"train_unique_chars\": len(train_unique_chars),\n","        \"eval_unique_chars\": len(eval_unique_chars),\n","        \"eval_only_chars\": len(eval_only_chars),\n","        \"eval_only_chars_list\": ''.join(sorted(eval_only_chars))[:100] if len(eval_only_chars) > 0 else \"\",\n","        \"train_avg_unit_length\": train_avg_len,\n","        \"eval_avg_unit_length\": eval_avg_len,\n","        \"train_unique_words\": len(train_unique_words),\n","        \"eval_unique_words\": len(eval_unique_words),\n","        \"eval_only_words\": len(eval_only_words),\n","        \"eval_only_words_pct\": eval_only_words_pct,\n","    }\n","\n","    print(\"\\nDistribution Validation:\")\n","    print(f\"Average unit length - Train: {train_avg_len:.1f}, Eval: {eval_avg_len:.1f} chars\")\n","    print(f\"Unique characters - Train: {len(train_unique_chars)}, Eval: {len(eval_unique_chars)}\")\n","\n","    if eval_only_chars:\n","        print(f\"Warning: {len(eval_only_chars)} characters appear in evaluation but not in training\")\n","        print(f\"First few eval-only chars: {validation['eval_only_chars_list'][:20]}...\")\n","\n","    print(f\"Unique words - Train: {len(train_unique_words)}, Eval: {len(eval_unique_words)}\")\n","    print(f\"Words only in evaluation set: {len(eval_only_words)} ({eval_only_words_pct:.1f}%)\")\n","\n","    return validation\n","\n","def main():\n","    parser = argparse.ArgumentParser(description=\"Split a corpus into training and evaluation sets\")\n","    parser.add_argument(\"--input_file\", type=str, required=True,\n","                        help=\"Path to the input corpus file\")\n","    parser.add_argument(\"--output_dir\", type=str, default=\"./\",\n","                        help=\"Directory to write output files\")\n","    parser.add_argument(\"--eval_size\", type=float, default=0.05,\n","                        help=\"Proportion of corpus to use for evaluation\")\n","    parser.add_argument(\"--random_seed\", type=int, default=42,\n","                        help=\"Random seed for reproducible splits\")\n","    parser.add_argument(\"--sentence_level\", action=\"store_true\",\n","                        help=\"Split at sentence boundaries instead of line boundaries\")\n","\n","    args = argparse.Namespace(\n","        input_file=\"/content/drive/My Drive/Colab Notebooks/LRLs/yoruba/dataset/yo.txt\",\n","        output_dir=\"/content/drive/My Drive/Colab Notebooks/LRLs/yoruba/dataset\",\n","        eval_size=0.05,\n","        random_seed=42,\n","        sentence_level=True\n","    )\n","\n","    print(f\"Splitting corpus file: {args.input_file}\")\n","    print(f\"Evaluation set size: {args.eval_size * 100:.1f}%\")\n","    print(f\"Using {'sentence' if args.sentence_level else 'line'} level splitting\")\n","\n","    train_units, eval_units = split_corpus(\n","        args.input_file,\n","        args.eval_size,\n","        args.random_seed,\n","        args.sentence_level\n","    )\n","\n","    base_filename = os.path.basename(args.input_file)\n","    train_path, eval_path = write_output_files(\n","        train_units,\n","        eval_units,\n","        args.output_dir,\n","        base_filename\n","    )\n","\n","    validation = validate_data_distribution(train_units, eval_units)\n","\n","    print(f\"  Training corpus: {train_path}\")\n","    print(f\"  Fertility evaluation corpus: {eval_path}\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"UZZAjAaKgGv8"},"execution_count":null,"outputs":[]}]}